{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create functions and initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "# Store results of API call\n",
    "import json\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "fips = pd.read_csv('fips_codes.csv', delimiter=',', dtype = str)\n",
    "fips = fips.sort_values(by = 'Name')\n",
    "API_key = 'YOUR CENSUS BUREAU KEY GOES HERE'\n",
    "\n",
    "def LinkedIn_Monster_Job_Table(States, JobTitle, verbose = False):\n",
    "    df_columns = ['Title', 'Company', 'Link', 'City', 'State', 'Days Listed', 'Source']\n",
    "    final_df = pd.DataFrame(columns = df_columns)\n",
    "    \n",
    "    for State in States:\n",
    "        MonJob = JobTitle.replace(\" \", \"-\")\n",
    "        LInJob = JobTitle.replace(\" \", \"%20\")\n",
    "        IndeedJob = JobTitle.replace(\" \", \"+\")\n",
    "        if verbose == True:\n",
    "            print(f'Creating Jobs Table For {State}')\n",
    "\n",
    "        # Monster.com\n",
    "        URL = f'https://www.monster.com/jobs/search/?q={MonJob}&where={State}'\n",
    "        page = requests.get(URL)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        results = soup.find(id='ResultsContainer')\n",
    "        job_elems = results.find_all('section', class_='card-content')\n",
    "        df = pd.DataFrame(columns = df_columns)\n",
    "\n",
    "        for job_elem in job_elems:\n",
    "            title_elem = job_elem.find('h2', class_='title')\n",
    "            company_elem = job_elem.find('div', class_='company')\n",
    "            location_elem = job_elem.find('div', class_='location')\n",
    "            link_elem = job_elem.find('a')\n",
    "            time = job_elem.find('time')\n",
    "            if None in (title_elem, company_elem, location_elem, time):\n",
    "                continue\n",
    "            #if verbose == True:\n",
    "                #print(time.text.strip())\n",
    "            try:\n",
    "                time_mon = int(re.search(r'\\d+', time.text.strip()).group(0))\n",
    "            except:\n",
    "                time_mon = 0\n",
    "            df = df.append({'Title': title_elem.text.strip(),\n",
    "                            'Company': company_elem.text.strip(),\n",
    "                            'Link': link_elem['href'],\n",
    "                            'City':location_elem.text.split(', ')[0].strip(),\n",
    "                            'State':State,\n",
    "                            'Days Listed': time_mon},\n",
    "                           ignore_index=True)\n",
    "        df['Source'] = 'Monster'\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(f'    Finished Monster Table For {State}')\n",
    "\n",
    "            \n",
    "            \n",
    "        # LinkedIn.com\n",
    "        URL_2 = f'https://www.linkedin.com/jobs/search/?keywords={LInJob}&location={State}%2C%20United%20States'\n",
    "        page_2 = requests.get(URL_2)\n",
    "        soup_2 = BeautifulSoup(page_2.content, 'html.parser')\n",
    "        results_2 = soup_2.find_all('li', class_='result-card')\n",
    "        df_2 = pd.DataFrame(columns = df_columns)\n",
    "\n",
    "        for job_elem in results_2:\n",
    "            title_elem = job_elem.find('h3', class_='job-result-card__title')\n",
    "            company_elem = job_elem.find('a', class_='job-result-card__subtitle-link')\n",
    "            location_elem = job_elem.find('span', class_='job-result-card__location')\n",
    "            link_elem = job_elem.find('a')\n",
    "            time = job_elem.find('time')\n",
    "            if None in (title_elem, company_elem, location_elem, time):\n",
    "                continue\n",
    "            df_2 = df_2.append({'Title': title_elem.text.strip(),\n",
    "                                'Company': company_elem.text.strip(),\n",
    "                                'Link': link_elem['href'],\n",
    "                                'City':location_elem.text.split(', ')[0].strip(),\n",
    "                                'State':State,\n",
    "                                'Days Listed': time.text.strip()},\n",
    "                               ignore_index=True)\n",
    "        df_2['Source'] = 'LinkedIn'\n",
    "\n",
    "        info_dict = {}\n",
    "        for info in df_2['Days Listed'].unique():\n",
    "            info_break = info.split()\n",
    "            if info_break[1] in ['minute', 'minutes']:\n",
    "                info_dict.update([(info, (1/1440)*int(info_break[0]))])\n",
    "            if info_break[1] in ['hour', 'hours']:\n",
    "                info_dict.update([(info, (1/24)*int(info_break[0]))])\n",
    "            elif info_break[1] in ['day', 'days']:\n",
    "                info_dict.update([(info, 1*int(info_break[0]))])\n",
    "            elif info_break[1] in ['week', 'weeks']:\n",
    "                info_dict.update([(info, 7*int(info_break[0]))])\n",
    "            elif info_break[1] in ['month', 'months']:\n",
    "                info_dict.update([(info, 30*int(info_break[0]))])\n",
    "            elif info_break[1] in ['year', 'years']:\n",
    "                info_dict.update([(info, 365*int(info_break[0]))])\n",
    "\n",
    "        df_2 = df_2.replace({'Days Listed': info_dict})\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(f'    Finished LinkedIn Table For {State}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Indeed.com    \n",
    "        URL_3 = f'https://www.indeed.com/jobs?q={IndeedJob}&l={State}'\n",
    "        page_3 = requests.get(URL_3)\n",
    "        soup_3 = BeautifulSoup(page_3.content, 'html.parser')\n",
    "        results_3 = soup_3.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "        df_3 = pd.DataFrame(columns = df_columns)\n",
    "        \n",
    "        for job_elem in results_3:\n",
    "            title_elem = job_elem.find('h2', class_='title')\n",
    "            company_elem = job_elem.find('span', class_='company')\n",
    "            location_elem = job_elem.find('span', class_='location')\n",
    "            link_elem = job_elem.find('a')\n",
    "            time = job_elem.find('span', class_='date')\n",
    "            if None in (title_elem, company_elem, location_elem, time):\n",
    "                continue\n",
    "            try:\n",
    "                time_mon = int(re.search(r'\\d+', time.text.strip()).group(0))\n",
    "            except:\n",
    "                time_mon = 0\n",
    "            df_3 = df_3.append({'Title': title_elem.text.strip(),\n",
    "                                'Company': company_elem.text.strip(),\n",
    "                                'Link': 'https://www.indeed.com' + link_elem['href'],\n",
    "                                'City':location_elem.text.split(', ')[0].strip(),\n",
    "                                'State':State,\n",
    "                                'Days Listed': time_mon},\n",
    "                               ignore_index=True)\n",
    "        df_3['Source'] = 'Indeed'\n",
    "        \n",
    "        #print(df_3)\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(f'    Finished Indeed Table For {State}')\n",
    "\n",
    "        final_df = pd.concat([final_df, df, df_2, df_3], ignore_index = True, sort = False).sort_values(by = 'Company', ascending = True)\n",
    "        if verbose == True:\n",
    "            print(f'Finished creating Jobs Table For {State} \\n')\n",
    "    if verbose == True:\n",
    "            print(f'Combined Jobs Tables For {States} \\n')\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Census_Place_Jobs_Table(variableCodes, \n",
    "                            variableNames, \n",
    "                            states, \n",
    "                            replace_dict, \n",
    "                            job_search,\n",
    "                            year = 2018,\n",
    "                            verbose = False,\n",
    "                            expand = False):\n",
    "    if verbose == True:\n",
    "        print(f'Creating Pops Table For {states}')\n",
    "    states.sort()\n",
    "    fips = pd.read_csv('fips_codes.csv', delimiter=',', dtype = str)\n",
    "    fips = fips.sort_values(by = 'Name')\n",
    "    state_code = fips['Fips'][fips.Name.isin(states)].to_string(header=False,index=False).split('\\n')\n",
    "    state_code = ','.join(state_code).replace(' ','')\n",
    "    apiResponse = requests.get(f'https://api.census.gov/data/{year}/acs/acs5?get=NAME,{variableCodes.replace(\" \", \"\")}&for=place:*&in=state:{state_code.replace(\" \", \"\")}&key={API_key}')\n",
    "    formattedResponse = json.loads(apiResponse.text)[1:]\n",
    "    Pops = pd.DataFrame(columns = json.loads(apiResponse.text)[0], data = formattedResponse)\n",
    "    \n",
    "    Pops.columns = variableNames\n",
    "    if verbose == True:\n",
    "        #print(Pops)\n",
    "        print(f'    Fixing Pops Table City Names For {states}')\n",
    "    Pops['City'] = Pops['City'].str.split(', ', n = 0, expand = True)\n",
    "    f = lambda x: ' '.join([item for item in x.split() if item not in ['city', 'town', 'township', 'CDP']])\n",
    "    Pops['City'] = Pops['City'].apply(f)\n",
    "    if verbose == True:\n",
    "        #print(Pops)\n",
    "        print(f'    Fixed Pops Table City Names For {states}')\n",
    "    \n",
    "    if verbose == True:\n",
    "        #print(Pops)\n",
    "        print(f'Finished Pops Table For {states}\\n')\n",
    "\n",
    "    Jobs = LinkedIn_Monster_Job_Table(states,\n",
    "                                      job_search,\n",
    "                                      verbose = verbose)\n",
    "    Jobs.City = Jobs.City.str.title()\n",
    "    Jobs = Jobs.replace({'City':replace_dict})\n",
    "    states_dict = {}\n",
    "    for stateC, stateN in zip(state_code.split(','), states):\n",
    "        states_dict[stateC] = stateN\n",
    "    print(states_dict)\n",
    "    Pops = Pops.replace({'State':states_dict})\n",
    "    print(Pops)\n",
    "    if verbose == True:\n",
    "        print(f'Combining Jobs and Pops Tables For {states}')\n",
    "    Final = pd.merge(Pops, Jobs, on = ['City', 'State'], how = 'right')\n",
    "    if verbose == True:\n",
    "        print(f'Finished Combining Jobs and Pops Tables For {states}')\n",
    "    Final['Date'] = pd.to_datetime(date.today()) - pd.to_timedelta(Final['Days Listed'], unit=\"D\")\n",
    "    if expand == True:\n",
    "        return Jobs, Pops, Final\n",
    "    return Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run example with 'Data Science' job string and Arizona, Colorado, Idaho, Montana, Nevada, Oregon, Utah, and Washington listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Pops Table For ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington']\n",
      "    Fixing Pops Table City Names For ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington']\n",
      "    Fixed Pops Table City Names For ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington']\n",
      "Finished Pops Table For ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington']\n",
      "\n",
      "Creating Jobs Table For Arizona\n",
      "    Finished Monster Table For Arizona\n",
      "    Finished LinkedIn Table For Arizona\n",
      "    Finished Indeed Table For Arizona\n",
      "Finished creating Jobs Table For Arizona \n",
      "\n",
      "Creating Jobs Table For Colorado\n",
      "    Finished Monster Table For Colorado\n",
      "    Finished LinkedIn Table For Colorado\n",
      "    Finished Indeed Table For Colorado\n",
      "Finished creating Jobs Table For Colorado \n",
      "\n",
      "Creating Jobs Table For Idaho\n",
      "    Finished Monster Table For Idaho\n",
      "    Finished LinkedIn Table For Idaho\n",
      "    Finished Indeed Table For Idaho\n",
      "Finished creating Jobs Table For Idaho \n",
      "\n",
      "Creating Jobs Table For Montana\n",
      "    Finished Monster Table For Montana\n",
      "    Finished LinkedIn Table For Montana\n",
      "    Finished Indeed Table For Montana\n",
      "Finished creating Jobs Table For Montana \n",
      "\n",
      "Creating Jobs Table For Nevada\n",
      "    Finished Monster Table For Nevada\n",
      "    Finished LinkedIn Table For Nevada\n",
      "    Finished Indeed Table For Nevada\n",
      "Finished creating Jobs Table For Nevada \n",
      "\n",
      "Creating Jobs Table For Oregon\n",
      "    Finished Monster Table For Oregon\n",
      "    Finished LinkedIn Table For Oregon\n",
      "    Finished Indeed Table For Oregon\n",
      "Finished creating Jobs Table For Oregon \n",
      "\n",
      "Creating Jobs Table For Utah\n",
      "    Finished Monster Table For Utah\n",
      "    Finished LinkedIn Table For Utah\n",
      "    Finished Indeed Table For Utah\n",
      "Finished creating Jobs Table For Utah \n",
      "\n",
      "Creating Jobs Table For Washington\n",
      "    Finished Monster Table For Washington\n",
      "    Finished LinkedIn Table For Washington\n",
      "    Finished Indeed Table For Washington\n",
      "Finished creating Jobs Table For Washington \n",
      "\n",
      "Combined Jobs Tables For ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington'] \n",
      "\n",
      "{'04': 'Arizona', '08': 'Colorado', '16': 'Idaho', '30': 'Montana', '32': 'Nevada', '41': 'Oregon', '49': 'Utah', '53': 'Washington'}\n",
      "                City Population    Median Age Median Income  \\\n",
      "0            Clinton        875          41.1         58393   \n",
      "1         Frenchtown       2330          38.7         65054   \n",
      "2          Lewistown       5895          44.8         42247   \n",
      "3            Lincoln        898          45.9         29250   \n",
      "4           Drummond        304          36.5         35893   \n",
      "...              ...        ...           ...           ...   \n",
      "2955     Yellow Pine          0  -666666666.0    -666666666   \n",
      "2956  Hidden Springs       2764          32.7        133409   \n",
      "2957        Elk City         83          65.6         35526   \n",
      "2958        Parkline         50          58.7         36667   \n",
      "2959           Tyhee       1266          36.6         84526   \n",
      "\n",
      "     Median Monthly Housing Costs Median Home Value    State Place ID  \n",
      "0                             830            217300  Montana    15475  \n",
      "1                            1391            309200  Montana    29350  \n",
      "2                             710            111700  Montana    43375  \n",
      "3                             635            164900  Montana    43675  \n",
      "4                             578            107600  Montana    21850  \n",
      "...                           ...               ...      ...      ...  \n",
      "2955                   -666666666        -666666666    Idaho    88660  \n",
      "2956                         1727            425900    Idaho    37500  \n",
      "2957                          776             72000    Idaho    25030  \n",
      "2958                          500            137500    Idaho    60880  \n",
      "2959                          832            236500    Idaho    83170  \n",
      "\n",
      "[2960 rows x 8 columns]\n",
      "Combining Jobs and Pops Tables For ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington']\n",
      "Finished Combining Jobs and Pops Tables For ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Population</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Median Income</th>\n",
       "      <th>Median Monthly Housing Costs</th>\n",
       "      <th>Median Home Value</th>\n",
       "      <th>State</th>\n",
       "      <th>Place ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Link</th>\n",
       "      <th>Days Listed</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wolf Point</td>\n",
       "      <td>2799</td>\n",
       "      <td>31.5</td>\n",
       "      <td>44276</td>\n",
       "      <td>533</td>\n",
       "      <td>101700</td>\n",
       "      <td>Montana</td>\n",
       "      <td>81475</td>\n",
       "      <td>Medical Technologist / MLT, MT, MLS</td>\n",
       "      <td>McCall and Lee</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/medical-tec...</td>\n",
       "      <td>30</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2020-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Cascade</td>\n",
       "      <td>653</td>\n",
       "      <td>54.0</td>\n",
       "      <td>42112</td>\n",
       "      <td>630</td>\n",
       "      <td>131000</td>\n",
       "      <td>Montana</td>\n",
       "      <td>12775</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Fulcrum Worldwide</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>3</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2020-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Kalispell</td>\n",
       "      <td>22621</td>\n",
       "      <td>35.9</td>\n",
       "      <td>47362</td>\n",
       "      <td>846</td>\n",
       "      <td>214100</td>\n",
       "      <td>Montana</td>\n",
       "      <td>40075</td>\n",
       "      <td>Health Insurance Agent - Work when &amp; where you...</td>\n",
       "      <td>Assurance</td>\n",
       "      <td>https://job-openings.monster.com/health-insura...</td>\n",
       "      <td>30</td>\n",
       "      <td>Monster</td>\n",
       "      <td>2020-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Great Falls</td>\n",
       "      <td>58990</td>\n",
       "      <td>38.6</td>\n",
       "      <td>45620</td>\n",
       "      <td>760</td>\n",
       "      <td>168900</td>\n",
       "      <td>Montana</td>\n",
       "      <td>32800</td>\n",
       "      <td>Health Insurance Agent - Work when &amp; where you...</td>\n",
       "      <td>Assurance</td>\n",
       "      <td>https://job-openings.monster.com/health-insura...</td>\n",
       "      <td>30</td>\n",
       "      <td>Monster</td>\n",
       "      <td>2020-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Great Falls</td>\n",
       "      <td>58990</td>\n",
       "      <td>38.6</td>\n",
       "      <td>45620</td>\n",
       "      <td>760</td>\n",
       "      <td>168900</td>\n",
       "      <td>Montana</td>\n",
       "      <td>32800</td>\n",
       "      <td>On-Demand Health Insurance Agent - Think Uber ...</td>\n",
       "      <td>Assurance</td>\n",
       "      <td>https://job-openings.monster.com/on-demand-hea...</td>\n",
       "      <td>30</td>\n",
       "      <td>Monster</td>\n",
       "      <td>2020-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>Greater Phoenix Area</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Tech Finders</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2020-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>Curtin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>The Voleon Group</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>30</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2020-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>Bayview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Scientist</td>\n",
       "      <td>United States Department of Defense</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/computer-sc...</td>\n",
       "      <td>90</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2020-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>Bayview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operations Research</td>\n",
       "      <td>United States Department of Defense</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/operations-...</td>\n",
       "      <td>90</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2020-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Director, Application Development</td>\n",
       "      <td>University Of Minnesota</td>\n",
       "      <td>https://job-openings.monster.com/senior-direct...</td>\n",
       "      <td>23</td>\n",
       "      <td>Monster</td>\n",
       "      <td>2020-06-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     City Population Median Age Median Income  \\\n",
       "0              Wolf Point       2799       31.5         44276   \n",
       "1                 Cascade        653       54.0         42112   \n",
       "2               Kalispell      22621       35.9         47362   \n",
       "3             Great Falls      58990       38.6         45620   \n",
       "4             Great Falls      58990       38.6         45620   \n",
       "..                    ...        ...        ...           ...   \n",
       "452  Greater Phoenix Area        NaN        NaN           NaN   \n",
       "453                Curtin        NaN        NaN           NaN   \n",
       "454               Bayview        NaN        NaN           NaN   \n",
       "455               Bayview        NaN        NaN           NaN   \n",
       "456           Minneapolis        NaN        NaN           NaN   \n",
       "\n",
       "    Median Monthly Housing Costs Median Home Value     State Place ID  \\\n",
       "0                            533            101700   Montana    81475   \n",
       "1                            630            131000   Montana    12775   \n",
       "2                            846            214100   Montana    40075   \n",
       "3                            760            168900   Montana    32800   \n",
       "4                            760            168900   Montana    32800   \n",
       "..                           ...               ...       ...      ...   \n",
       "452                          NaN               NaN   Arizona      NaN   \n",
       "453                          NaN               NaN    Oregon      NaN   \n",
       "454                          NaN               NaN     Idaho      NaN   \n",
       "455                          NaN               NaN     Idaho      NaN   \n",
       "456                          NaN               NaN  Colorado      NaN   \n",
       "\n",
       "                                                 Title  \\\n",
       "0                  Medical Technologist / MLT, MT, MLS   \n",
       "1                                       Data Scientist   \n",
       "2    Health Insurance Agent - Work when & where you...   \n",
       "3    Health Insurance Agent - Work when & where you...   \n",
       "4    On-Demand Health Insurance Agent - Think Uber ...   \n",
       "..                                                 ...   \n",
       "452                              Senior Data Scientist   \n",
       "453                                       Data Analyst   \n",
       "454                                 Computer Scientist   \n",
       "455                                Operations Research   \n",
       "456           Senior Director, Application Development   \n",
       "\n",
       "                                 Company  \\\n",
       "0                         McCall and Lee   \n",
       "1                      Fulcrum Worldwide   \n",
       "2                              Assurance   \n",
       "3                              Assurance   \n",
       "4                              Assurance   \n",
       "..                                   ...   \n",
       "452                         Tech Finders   \n",
       "453                     The Voleon Group   \n",
       "454  United States Department of Defense   \n",
       "455  United States Department of Defense   \n",
       "456              University Of Minnesota   \n",
       "\n",
       "                                                  Link Days Listed    Source  \\\n",
       "0    https://www.linkedin.com/jobs/view/medical-tec...          30  LinkedIn   \n",
       "1    https://www.linkedin.com/jobs/view/data-scient...           3  LinkedIn   \n",
       "2    https://job-openings.monster.com/health-insura...          30   Monster   \n",
       "3    https://job-openings.monster.com/health-insura...          30   Monster   \n",
       "4    https://job-openings.monster.com/on-demand-hea...          30   Monster   \n",
       "..                                                 ...         ...       ...   \n",
       "452  https://www.linkedin.com/jobs/view/senior-data...           3  LinkedIn   \n",
       "453  https://www.linkedin.com/jobs/view/data-analys...          30  LinkedIn   \n",
       "454  https://www.linkedin.com/jobs/view/computer-sc...          90  LinkedIn   \n",
       "455  https://www.linkedin.com/jobs/view/operations-...          90  LinkedIn   \n",
       "456  https://job-openings.monster.com/senior-direct...          23   Monster   \n",
       "\n",
       "          Date  \n",
       "0   2020-06-16  \n",
       "1   2020-07-13  \n",
       "2   2020-06-16  \n",
       "3   2020-06-16  \n",
       "4   2020-06-16  \n",
       "..         ...  \n",
       "452 2020-07-13  \n",
       "453 2020-06-16  \n",
       "454 2020-04-17  \n",
       "455 2020-04-17  \n",
       "456 2020-06-23  \n",
       "\n",
       "[457 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Census_Place_Jobs_Table('B01001_001E, B01002_001E, B19013_001E, B25105_001E, B25077_001E', \n",
    "                        ['City',\n",
    "                         'Population',\n",
    "                         'Median Age',\n",
    "                         'Median Income',\n",
    "                         'Median Monthly Housing Costs',\n",
    "                         'Median Home Value',\n",
    "                         'State',\n",
    "                         'Place ID'],\n",
    "                        ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'Oregon', 'Utah', 'Washington'],\n",
    "                        {'Salt Lake': 'Salt Lake City',\n",
    "                         'Salt Lake City Metropolitan Area': 'Salt Lake City',\n",
    "                         'SLC': 'Salt Lake City',\n",
    "                         'Slc': 'Salt Lake City',\n",
    "                         'Hill AFB': 'Roy',\n",
    "                         'Hill Afb': 'Roy',\n",
    "                         'Denver Metropolitan Area': 'Denver',\n",
    "                         'Boise': 'Boise City',\n",
    "                         \"Coeur D'Alene\": \"Coeur d'Alene\",\n",
    "                         \"Coeur D Alene\": \"Coeur d'Alene\"},\n",
    "                        'Data Scientist',\n",
    "                        year = 2018,\n",
    "                        verbose = True,\n",
    "                        expand = False)\n",
    "\n",
    "#View table\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
